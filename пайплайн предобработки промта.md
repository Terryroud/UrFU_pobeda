Raw text
   │
   ▼
[Deobfuscation + homoglyph mapping]  ← борьба с шифрованием и "1gnor3"
   │
   ▼
[Normalization (lower, punctuation, emoji)]
   │
   ▼
[Tokenization + Lemmatization (NLTK+pymorphy2)]
   │
   ▼
[HeuristicFilter] — жёсткие правила (regex, словари)
   │
   ▼
[Embedding similarity] — soft matching
   │
   ▼
[Classifier / Risk scoring]


```
def preprocess_text(text: str) -> str:
    # 1. Lowercasing
    text = text.lower()

    # 2. Очистка от html, emoji, пунктуации
    text = remove_html_tags(text)
    text = remove_emojis(text)
    text = remove_punctuation(text)

    # 3. Токенизация (NLTK)
    tokens = nltk.word_tokenize(text, language="russian")

    # 4. Лемматизация
    # 4.1 Быстрая нормализация для английского (WordNetLemmatizer)
    tokens = [lemmatizer_en.lemmatize(tok) for tok in tokens if lang == "en"]

    # 4.2 Для русского — pymorphy2
    tokens = [morph.parse(tok)[0].normal_form for tok in tokens if lang == "ru"]

    # 5. (опционально) Удаление стоп-слов
    tokens = [t for t in tokens if t not in stopwords]

    # 6. Сбор обратно
    return " ".join(tokens)
```